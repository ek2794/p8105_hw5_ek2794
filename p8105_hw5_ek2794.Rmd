---
title: "Homework 5"
output: github_document
---

Let's set up our homework!
```{r}
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(stringr)
library(broom)
library(patchwork)
set.seed(1)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


```
## Here I downloaded the dataset from Github. I created a separated city_state variable to identify each individual city/ There was a Tulsa, AL written accidentally, which should have been OK as the state so this was mutated with the 'case_when' funciton, which led us to have 50 unique cities. Then we grouped by each city/state and made a group of the unsolved cases which comprise of 'Closed by arrest' and 'Open/No arrest'  and a total number of homicides group. 

I created a separate baltimore dataset by filtering out Baltimore, MD from the prior dataset.


```{r}
website = ("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

unsolved_crimes = read_csv(website) %>%
  janitor::clean_names() %>%
  unite(city_state, c(city, state), sep = ", ") %>%
    mutate(
      city_state = case_when(city_state == "Tulsa, AL" ~ "Tulsa, OK", TRUE~city_state)) %>%
    group_by(city_state) %>%
    summarize(
      unsolved = sum(disposition == "Closed by arrest" | disposition == "Open/No arrest"),
      total = n())
      
baltimore = unsolved_crimes %>%
  filter(city_state == "Baltimore, MD")

```


##Here I created a function for proptest where x = the # of unsolved crimes and n = total number of homicides. I used the 'broom::tidy' function to create a workable tibble and selected the estimate, low, and high confidence interval. I created the proptest into a function in order to be able to be applied to the rest of the cities.##

```{r}

proptest = function(unsolved, total) {

    prop.test(unsolved, total, p = 0.5, alternative = "two.sided") %>%
    broom::tidy() %>%
    select(estimate, conf.low, conf.high)
}

```


##I successfully ran the proptest function with the baltimore dataset. Subsequently, I used the map function to apply the 'prop.test' function to the larger unsolved_crimes dataset, and used the broom::tidy to create a tidy dataframe. Subsequently, I unnested the dataset and then selected the same 3 variables again to generate a dataframe of estimated proportions and CIs for each city. ##


```{r}

baltimore_results = 
  proptest(
    pull(baltimore, unsolved), 
    pull(baltimore, total)) 


cities_results =
  unsolved_crimes %>%
  mutate(
  prop_data = map2(unsolved, total, ~prop.test(.x, .y) %>%
    broom::tidy())
) %>%
  unnest(prop_data) %>%
  select(city_state, estimate, conf.low, conf.high) %>%
  rename(
    conf_low = conf.low,
    conf_high = conf.high)
  
cities_results

```

##Using the results from the tidy dataframe above, I plotted the each city in descending order of estimates using ggplot. The confidence intervals are demonstrated with ymin as conf_low and ymax as conf_high illustrated with error bars. The fct_reorder function was used to organize the cities in this descending order.##

```{r}
cities_results %>%
  mutate(
  city_state = fct_reorder(city_state, estimate, .desc = TRUE)) %>%
  ggplot(
    aes(x = city_state, y = estimate)) + 
    geom_point() + 
    geom_errorbar(aes(ymin = conf_low, ymax = conf_high)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



##PROBLEM 3 


##Here we create a function within a function. The function on the top is the t-test function that we will feed the dataframe into. Below we create a 'generate_results' function that applies the t test to a generated dataset with a for loop. 

Below the t test function we generate the dataset by establishing the mu of 0, standard deviation of 5, iterations of 5000, and observations of 30 per dataset. We create a for loop to be able to run this 5000 times and generate a new list with this. 

Next, we create a tibble which pulls out the prior data and applies the t-test function. This data is unnested. Subsequently the estimate/proportions and p-values are pulled out. This tibble is piped into the final tibble which gives summary statistics that shows whether or not the null was rejected with a p-value of <0.05 demonstrated with the rej variable. From this the proportion of times the null hypothesis was rejected is created and the average mu hat is created with the average of the proportions. 

Finally, we made a tibble of mus 0 to 6 and ran the map function to apply the entire generate_results function  so that a new tibble could be made with the summary statistics of all the 7 different mus. 

 
```{r}

t_test_clean = function(df){
  out_df <- t.test(df,
         alternative = c("two.sided"),
         mu = 0, 
         conf.level = 0.95) %>%
    broom::tidy()
  return(out_df)
}



generate_results = function(mu = 0, 
                            sigma = 5, 
                            n_iter = 5000, 
                            n_obs = 30){

new_list = list()



for (i in 1:n_iter) {
  temp_vec = rnorm(n = n_obs, mean = mu, sd = sigma)
  new_list[[i]] = temp_vec
}




stats_tib = 
  tibble(
    data = new_list
  ) %>%
  mutate(
    ttest_results = map(.x = data, ~t_test_clean(.x))
  ) %>%
  unnest(ttest_results) %>%
  janitor::clean_names() %>%
  select(estimate, p_value)

fin_tib = stats_tib %>%
  mutate(
    rej = p_value < 0.05
  ) %>%
  summarize(
    rej_value = rej,
    tot = n(),
    tot_rej = sum(rej),
    prop_rej = tot_rej/tot,
    avg_mu_hat = mean(estimate)
  ) %>%
return(fin_tib)
}



new_tib = 
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    results = map(.x = mu, ~generate_results(mu = .x))) %>%
      unnest(results)

  

```


##Below we ran the same functions and for loop however added an additional step of filtering out only data that were rejected. We created a ggplot that demonstrates the estimate of m-hat with the different mu values. ##



```{r}

t_test_clean = function(df){
  out_df <- t.test(df,
         alternative = c("two.sided"),
         mu = 0, 
         conf.level = 0.95) %>%
    broom::tidy()
  return(out_df)
}



generate_results2 = function(mu = 0, 
                            sigma = 5, 
                            n_iter = 50, 
                            n_obs = 30){

new_list2 = list()



for (i in 1:n_iter) {
  temp_vec = rnorm(n = n_obs, mean = mu, sd = sigma)
  new_list2[[i]] = temp_vec
}




stats_tib2 = 
  tibble(
    data = new_list2
  ) %>%
  mutate(
    ttest_results = map(.x = data, ~t_test_clean(.x))
  ) %>%
  unnest(ttest_results) %>%
  janitor::clean_names() %>%
  select(estimate, p_value)

fin_tib2 = stats_tib2 %>%
  mutate(
    rej = p_value < 0.05
  ) %>%
  filter(p_value < 0.05) %>%
  summarize(
    tot = n(),
    tot_rej = sum(rej),
    prop_rej = tot_rej/tot,
    avg_mu_hat = mean(estimate)
  ) %>%
return(fin_tib2)
}



new_tib2 = 
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>%
  mutate(
    results2 = map(.x = mu, ~generate_results2(mu = .x))) %>%
      unnest(results2)



rejectedonly = new_tib2 %>%
  ggplot(aes(x = mu, y = avg_mu_hat)) +
  geom_point(aes(color = mu)) +
  labs(x = "Mu", y = "Estimate of Mu-hat") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
    ggtitle("Mu-hat at Mu for Rejected Cases")
  
  
```

##Below we create another ggplot for the original dataset showing the estimate of mu hats with the different mus. Using patchwork, these graphs are displayed side by side.##

```{r}

all = new_tib %>%
  ggplot(aes(x = mu, y = avg_mu_hat)) +
  geom_point(aes(color = mu)) +
  labs(x = "Mu", y = "Estimate of Mu-hat") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
    ggtitle("Mu-hat at Mu for All Cases")
  
all + rejectedonly
```


